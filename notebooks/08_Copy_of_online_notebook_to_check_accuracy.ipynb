{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41a192b6",
   "metadata": {},
   "source": [
    "### Description\n",
    "\n",
    "This is the May 2025 calories prediction competition.\n",
    "\n",
    "### Files\n",
    "1. train.csv\n",
    "2. test.csv\n",
    "3. sample_submission.csv\n",
    "\n",
    "### Evaluation\n",
    "\n",
    "The evaluation metric is the RMSLE.\n",
    "\n",
    "Submission File\n",
    "For each id in the test set, you must predict the number of minutes listened. The file should contain a header and have the following format:\n",
    "\n",
    "- id,Listening_Time_minutes\n",
    "- 26570,0.2\n",
    "- 26571,0.1\n",
    "- 26572,0.9\n",
    "- etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccae698",
   "metadata": {},
   "source": [
    "## Package Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7314a528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general python libraries\n",
    "import time\n",
    "import sys\n",
    "import datetime\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "# dataframe and data manipulation library\n",
    "import pandas as pd\n",
    "\n",
    "# visualisation and EDA libraries\n",
    "import matplotlib.pyplot as  plt\n",
    "import seaborn as sns\n",
    "\n",
    "# machine learning libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import TargetEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669de298",
   "metadata": {},
   "source": [
    "## Data Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e5e28c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_COLUMN = 'Calories'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7baff0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '../data/raw'\n",
    "df_train = pd.read_csv(f'{folder_path}/train.csv', index_col='id')\n",
    "df_test = pd.read_csv(f'{folder_path}/test.csv', index_col='id')\n",
    "df_sample_submission = pd.read_csv(f'{folder_path}/sample_submission.csv',index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a2f11ab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Heart_Rate</th>\n",
       "      <th>Body_Temp</th>\n",
       "      <th>Calories</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>36</td>\n",
       "      <td>189.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>64</td>\n",
       "      <td>163.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>39.7</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>51</td>\n",
       "      <td>161.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>39.8</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>20</td>\n",
       "      <td>192.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>40.7</td>\n",
       "      <td>140.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>female</td>\n",
       "      <td>38</td>\n",
       "      <td>166.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>40.6</td>\n",
       "      <td>146.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749995</th>\n",
       "      <td>male</td>\n",
       "      <td>28</td>\n",
       "      <td>193.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>40.9</td>\n",
       "      <td>230.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749996</th>\n",
       "      <td>female</td>\n",
       "      <td>64</td>\n",
       "      <td>165.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>40.5</td>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749997</th>\n",
       "      <td>male</td>\n",
       "      <td>60</td>\n",
       "      <td>162.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>40.9</td>\n",
       "      <td>221.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749998</th>\n",
       "      <td>male</td>\n",
       "      <td>45</td>\n",
       "      <td>182.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>40.3</td>\n",
       "      <td>109.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749999</th>\n",
       "      <td>female</td>\n",
       "      <td>39</td>\n",
       "      <td>171.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>40.6</td>\n",
       "      <td>103.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>750000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Sex  Age  Height  Weight  Duration  Heart_Rate  Body_Temp  Calories\n",
       "id                                                                            \n",
       "0         male   36   189.0    82.0      26.0       101.0       41.0     150.0\n",
       "1       female   64   163.0    60.0       8.0        85.0       39.7      34.0\n",
       "2       female   51   161.0    64.0       7.0        84.0       39.8      29.0\n",
       "3         male   20   192.0    90.0      25.0       105.0       40.7     140.0\n",
       "4       female   38   166.0    61.0      25.0       102.0       40.6     146.0\n",
       "...        ...  ...     ...     ...       ...         ...        ...       ...\n",
       "749995    male   28   193.0    97.0      30.0       114.0       40.9     230.0\n",
       "749996  female   64   165.0    63.0      18.0        92.0       40.5      96.0\n",
       "749997    male   60   162.0    67.0      29.0       113.0       40.9     221.0\n",
       "749998    male   45   182.0    91.0      17.0       102.0       40.3     109.0\n",
       "749999  female   39   171.0    65.0      19.0        97.0       40.6     103.0\n",
       "\n",
       "[750000 rows x 8 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b85c0179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Heart_Rate</th>\n",
       "      <th>Body_Temp</th>\n",
       "      <th>Calories</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>36</td>\n",
       "      <td>189.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>64</td>\n",
       "      <td>163.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>39.7</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>51</td>\n",
       "      <td>161.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>39.8</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>20</td>\n",
       "      <td>192.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>40.7</td>\n",
       "      <td>140.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>female</td>\n",
       "      <td>38</td>\n",
       "      <td>166.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>40.6</td>\n",
       "      <td>146.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749995</th>\n",
       "      <td>male</td>\n",
       "      <td>28</td>\n",
       "      <td>193.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>40.9</td>\n",
       "      <td>230.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749996</th>\n",
       "      <td>female</td>\n",
       "      <td>64</td>\n",
       "      <td>165.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>40.5</td>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749997</th>\n",
       "      <td>male</td>\n",
       "      <td>60</td>\n",
       "      <td>162.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>40.9</td>\n",
       "      <td>221.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749998</th>\n",
       "      <td>male</td>\n",
       "      <td>45</td>\n",
       "      <td>182.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>40.3</td>\n",
       "      <td>109.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749999</th>\n",
       "      <td>female</td>\n",
       "      <td>39</td>\n",
       "      <td>171.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>40.6</td>\n",
       "      <td>103.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>750000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Sex  Age  Height  Weight  Duration  Heart_Rate  Body_Temp  Calories\n",
       "id                                                                            \n",
       "0         male   36   189.0    82.0      26.0       101.0       41.0     150.0\n",
       "1       female   64   163.0    60.0       8.0        85.0       39.7      34.0\n",
       "2       female   51   161.0    64.0       7.0        84.0       39.8      29.0\n",
       "3         male   20   192.0    90.0      25.0       105.0       40.7     140.0\n",
       "4       female   38   166.0    61.0      25.0       102.0       40.6     146.0\n",
       "...        ...  ...     ...     ...       ...         ...        ...       ...\n",
       "749995    male   28   193.0    97.0      30.0       114.0       40.9     230.0\n",
       "749996  female   64   165.0    63.0      18.0        92.0       40.5      96.0\n",
       "749997    male   60   162.0    67.0      29.0       113.0       40.9     221.0\n",
       "749998    male   45   182.0    91.0      17.0       102.0       40.3     109.0\n",
       "749999  female   39   171.0    65.0      19.0        97.0       40.6     103.0\n",
       "\n",
       "[750000 rows x 8 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "84bf769d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex            object\n",
       "Age             int64\n",
       "Height        float64\n",
       "Weight        float64\n",
       "Duration      float64\n",
       "Heart_Rate    float64\n",
       "Body_Temp     float64\n",
       "Calories      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe538dc",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dc21fc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df):\n",
    "    \n",
    "    # Encode sex as binary flag\n",
    "    gender_mapping = {\n",
    "        'male': 0,\n",
    "        'female': 1\n",
    "    }\n",
    "    df['is_female'] = df['Sex'].map(gender_mapping)\n",
    "    df = df.drop(columns=['Sex'])\n",
    "\n",
    "    \n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8f439d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(X: pd.DataFrame):\n",
    "\n",
    "    X = feature_engineering(X)\n",
    "\n",
    "    return X # Enabled this to stop warnings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "308af2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_encoding(X_train, y_train, X_test):\n",
    "\n",
    "    ### TARGET ENCODING\n",
    "    # Categorical Columns\n",
    "    categorical_columns = [\"Genre\",\"Publication_Day\",\"Episode_Sentiment\",\"Publication_Time\",\"Podcast_Name\"]\n",
    "    categorical_encoded_columns = [column_name + '_TE' for column_name in categorical_columns]\n",
    "\n",
    "    encoder = TargetEncoder(categories='auto', smooth='auto', cv=5, random_state=42)\n",
    "    encoder.fit(X_train[categorical_columns], y_train)\n",
    "    X_train[categorical_encoded_columns] = encoder.transform(X_train[categorical_columns])\n",
    "    X_test[categorical_encoded_columns] = encoder.transform(X_test[categorical_columns])    \n",
    "\n",
    "    # # Interaction Columns\n",
    "    # interaction_features = [\n",
    "    #     ('Publication_Day','Publication_Time')\n",
    "    # ]\n",
    "\n",
    "    # interaction_features_to_be_encoded = []\n",
    "    # for feature_1, feature_2 in interaction_features:\n",
    "    #     feature_name = feature_1 + '_' + feature_2 + '_TE'\n",
    "    #     X_train[feature_name] = (X_train[feature_1].astype('str') + '_' + X_train[feature_2].astype('str')).astype('category')\n",
    "    #     X_test[feature_name] = (X_test[feature_1].astype('str') + '_' + X_test[feature_2].astype('str')).astype('category')\n",
    "    #     interaction_features_to_be_encoded.append(feature_name)\n",
    "    \n",
    "    # encoder = TargetEncoder(categories='auto', smooth='auto', cv=5, random_state=42)\n",
    "    # encoder.fit(X_train[interaction_features_to_be_encoded], y_train)\n",
    "    # X_train[interaction_features_to_be_encoded] = encoder.transform(X_train[interaction_features_to_be_encoded])\n",
    "    # X_test[interaction_features_to_be_encoded] = encoder.transform(X_test[interaction_features_to_be_encoded])    \n",
    "\n",
    "    # # Fitting encoder and transforming data\n",
    "\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9ff51658",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocessing(X:pd.DataFrame):\n",
    "\n",
    "    columns_to_drop = [\n",
    "        # 'Sex', # Already dropped in feature engineering\n",
    "        # 'Age',\n",
    "        # 'Height',\n",
    "        # 'Weight',\n",
    "        # 'Duration',\n",
    "        # 'Heart_Rate',\n",
    "        # 'Body_Temp',\n",
    "        # 'Calories' # target variable\n",
    "    ]\n",
    "\n",
    "    X = X.drop(columns=columns_to_drop)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f759e220",
   "metadata": {},
   "source": [
    "## Model fitting\n",
    "\n",
    "### Train Test Split\n",
    "\n",
    "Splitting data into groupings for model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "84028e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import root_mean_squared_log_error\n",
    "\n",
    "def get_rmsle(preds,eval_data):\n",
    "\n",
    "    y_preds_negatives_removed = np.clip(preds, a_min= 0, a_max = np.inf)\n",
    "\n",
    "    rmsle = root_mean_squared_log_error(y_preds_negatives_removed, eval_data)\n",
    "\n",
    "    # Metric must have the following format to be accepted\n",
    "    # eval_name, eval_result, is_higher_better\n",
    "    return 'rmsle', rmsle, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ab862e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=3 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0016838659225225001, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0.0016838659225225001\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.816048559942313, reg_lambda=1.0 will be ignored. Current value: lambda_l2=6.816048559942313\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5600550938420944, subsample=0.9 will be ignored. Current value: bagging_fraction=0.5600550938420944\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7571066302658794, colsample_bytree=0.5 will be ignored. Current value: feature_fraction=0.7571066302658794\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=3 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0016838659225225001, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0.0016838659225225001\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.816048559942313, reg_lambda=1.0 will be ignored. Current value: lambda_l2=6.816048559942313\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5600550938420944, subsample=0.9 will be ignored. Current value: bagging_fraction=0.5600550938420944\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7571066302658794, colsample_bytree=0.5 will be ignored. Current value: feature_fraction=0.7571066302658794\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.071265\n",
      "[LightGBM] [Debug] init for col-wise cost 0.000001 seconds, init for row-wise cost 0.004584 seconds\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001384 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Debug] Using Dense Multi-Val Bin\n",
      "[LightGBM] [Info] Total Bins 360\n",
      "[LightGBM] [Info] Number of data points in the train set: 562500, number of used features: 7\n",
      "[LightGBM] [Debug] Use subset for bagging\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=3 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0016838659225225001, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0.0016838659225225001\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.816048559942313, reg_lambda=1.0 will be ignored. Current value: lambda_l2=6.816048559942313\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5600550938420944, subsample=0.9 will be ignored. Current value: bagging_fraction=0.5600550938420944\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7571066302658794, colsample_bytree=0.5 will be ignored. Current value: feature_fraction=0.7571066302658794\n",
      "[LightGBM] [Info] Start training from score 76.000000\n",
      "[LightGBM] [Debug] Re-bagging, using 314587 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 61 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 54 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 59 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 58 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 315254 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 59 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 57 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 62 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 54 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 314538 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 54 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 56 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 51 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 58 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 314871 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 56 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 57 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 315482 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 54 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 57 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 59 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 314926 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 57 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 56 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 61 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 56 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 57 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 314770 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 50 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 56 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 314989 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 47 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 49 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 49 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 315855 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 47 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 49 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 47 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 315350 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 51 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 46 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 46 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 315366 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 61 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 61 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 315382 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 61 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 62 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 58 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 314531 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 62 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 6\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 64 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 56 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 58 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 315054 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 51 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 62 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 61 and depth = 6\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 64 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 62 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 314774 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 49 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 57 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 58 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 314918 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 59 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 62 and depth = 6\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 64 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 57 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 315370 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 62 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 59 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 61 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 314772 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 6\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 64 and depth = 6\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 64 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 50 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 59 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 314249 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 56 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 61 and depth = 6\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 64 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 61 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 315444 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 62 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 51 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 56 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 51 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 62 and depth = 6\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0016838659225225001, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0.0016838659225225001\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=3 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7571066302658794, colsample_bytree=0.5 will be ignored. Current value: feature_fraction=0.7571066302658794\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5600550938420944, subsample=0.9 will be ignored. Current value: bagging_fraction=0.5600550938420944\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.816048559942313, reg_lambda=1.0 will be ignored. Current value: lambda_l2=6.816048559942313\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0016838659225225001, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0.0016838659225225001\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=3 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7571066302658794, colsample_bytree=0.5 will be ignored. Current value: feature_fraction=0.7571066302658794\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5600550938420944, subsample=0.9 will be ignored. Current value: bagging_fraction=0.5600550938420944\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.816048559942313, reg_lambda=1.0 will be ignored. Current value: lambda_l2=6.816048559942313\n",
      "--- Fold 1 Completed ---\n",
      "train_rmse, test_rmse -  0.06535850310274596 0.06565856492789343\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=3 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0016838659225225001, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0.0016838659225225001\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.816048559942313, reg_lambda=1.0 will be ignored. Current value: lambda_l2=6.816048559942313\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5600550938420944, subsample=0.9 will be ignored. Current value: bagging_fraction=0.5600550938420944\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7571066302658794, colsample_bytree=0.5 will be ignored. Current value: feature_fraction=0.7571066302658794\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=3 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0016838659225225001, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0.0016838659225225001\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.816048559942313, reg_lambda=1.0 will be ignored. Current value: lambda_l2=6.816048559942313\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5600550938420944, subsample=0.9 will be ignored. Current value: bagging_fraction=0.5600550938420944\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7571066302658794, colsample_bytree=0.5 will be ignored. Current value: feature_fraction=0.7571066302658794\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.071041\n",
      "[LightGBM] [Debug] init for col-wise cost 0.000001 seconds, init for row-wise cost 0.002627 seconds\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000910 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Debug] Using Dense Multi-Val Bin\n",
      "[LightGBM] [Info] Total Bins 356\n",
      "[LightGBM] [Info] Number of data points in the train set: 562500, number of used features: 7\n",
      "[LightGBM] [Debug] Use subset for bagging\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=3 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0016838659225225001, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0.0016838659225225001\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.816048559942313, reg_lambda=1.0 will be ignored. Current value: lambda_l2=6.816048559942313\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5600550938420944, subsample=0.9 will be ignored. Current value: bagging_fraction=0.5600550938420944\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7571066302658794, colsample_bytree=0.5 will be ignored. Current value: feature_fraction=0.7571066302658794\n",
      "[LightGBM] [Info] Start training from score 77.000000\n",
      "[LightGBM] [Debug] Re-bagging, using 314587 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 51 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 61 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 59 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 315254 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 59 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 62 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 61 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 57 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 314538 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 62 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 51 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 56 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 54 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 61 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 314871 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 59 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 315482 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 61 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 56 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 58 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 314926 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 57 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 58 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 57 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 314770 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 57 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 57 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 314989 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 56 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 49 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 315855 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 49 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 58 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 315350 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 57 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 58 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 315366 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 57 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 59 and depth = 6\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 64 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 51 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 315382 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 6\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 64 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 57 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 62 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 314531 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 61 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 62 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 51 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 56 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 315054 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 6\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 64 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 49 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 47 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 314774 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 58 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 51 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 58 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 314918 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 64 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 56 and depth = 6\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 64 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 54 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 315370 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 62 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 62 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 56 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 314772 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 62 and depth = 6\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 64 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 56 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 314249 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 58 and depth = 6\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 64 and depth = 6\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 64 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 62 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 315444 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 57 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 51 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 46 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 62 and depth = 6\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0016838659225225001, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0.0016838659225225001\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=3 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7571066302658794, colsample_bytree=0.5 will be ignored. Current value: feature_fraction=0.7571066302658794\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5600550938420944, subsample=0.9 will be ignored. Current value: bagging_fraction=0.5600550938420944\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.816048559942313, reg_lambda=1.0 will be ignored. Current value: lambda_l2=6.816048559942313\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0016838659225225001, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0.0016838659225225001\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=3 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7571066302658794, colsample_bytree=0.5 will be ignored. Current value: feature_fraction=0.7571066302658794\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5600550938420944, subsample=0.9 will be ignored. Current value: bagging_fraction=0.5600550938420944\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.816048559942313, reg_lambda=1.0 will be ignored. Current value: lambda_l2=6.816048559942313\n",
      "--- Fold 2 Completed ---\n",
      "train_rmse, test_rmse -  0.06553153810119922 0.0658928376189364\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=3 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0016838659225225001, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0.0016838659225225001\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.816048559942313, reg_lambda=1.0 will be ignored. Current value: lambda_l2=6.816048559942313\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5600550938420944, subsample=0.9 will be ignored. Current value: bagging_fraction=0.5600550938420944\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7571066302658794, colsample_bytree=0.5 will be ignored. Current value: feature_fraction=0.7571066302658794\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=3 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0016838659225225001, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0.0016838659225225001\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.816048559942313, reg_lambda=1.0 will be ignored. Current value: lambda_l2=6.816048559942313\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5600550938420944, subsample=0.9 will be ignored. Current value: bagging_fraction=0.5600550938420944\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7571066302658794, colsample_bytree=0.5 will be ignored. Current value: feature_fraction=0.7571066302658794\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.071264\n",
      "[LightGBM] [Debug] init for col-wise cost 0.000001 seconds, init for row-wise cost 0.002682 seconds\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000927 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Debug] Using Dense Multi-Val Bin\n",
      "[LightGBM] [Info] Total Bins 360\n",
      "[LightGBM] [Info] Number of data points in the train set: 562500, number of used features: 7\n",
      "[LightGBM] [Debug] Use subset for bagging\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=3 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0016838659225225001, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0.0016838659225225001\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.816048559942313, reg_lambda=1.0 will be ignored. Current value: lambda_l2=6.816048559942313\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5600550938420944, subsample=0.9 will be ignored. Current value: bagging_fraction=0.5600550938420944\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7571066302658794, colsample_bytree=0.5 will be ignored. Current value: feature_fraction=0.7571066302658794\n",
      "[LightGBM] [Info] Start training from score 77.000000\n",
      "[LightGBM] [Debug] Re-bagging, using 314587 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 61 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 59 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 315254 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 62 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 61 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 61 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 56 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 314538 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 59 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 56 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 57 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 58 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 314871 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 61 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 59 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 56 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 315482 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 59 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 54 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 61 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 58 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 314926 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 59 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 57 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 56 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 58 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 314770 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 56 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 56 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 314989 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 56 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 54 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 49 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 49 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 49 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 315855 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 43 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 34 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 58 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 315350 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 47 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 58 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 54 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 315366 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 59 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 59 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 57 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 58 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 51 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 315382 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 62 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 54 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 58 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 314531 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 61 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 62 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 62 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 61 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 315054 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 61 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 62 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 58 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 59 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 61 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 314774 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 62 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 62 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 61 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 61 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 314918 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 59 and depth = 6\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 64 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 315370 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 46 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 61 and depth = 6\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 64 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 50 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 314772 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 59 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 61 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 62 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 59 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 314249 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 64 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 62 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 62 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 6\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 64 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 315444 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 47 and depth = 6\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 64 and depth = 6\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 64 and depth = 6\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0016838659225225001, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0.0016838659225225001\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=3 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7571066302658794, colsample_bytree=0.5 will be ignored. Current value: feature_fraction=0.7571066302658794\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5600550938420944, subsample=0.9 will be ignored. Current value: bagging_fraction=0.5600550938420944\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.816048559942313, reg_lambda=1.0 will be ignored. Current value: lambda_l2=6.816048559942313\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0016838659225225001, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0.0016838659225225001\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=3 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7571066302658794, colsample_bytree=0.5 will be ignored. Current value: feature_fraction=0.7571066302658794\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5600550938420944, subsample=0.9 will be ignored. Current value: bagging_fraction=0.5600550938420944\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.816048559942313, reg_lambda=1.0 will be ignored. Current value: lambda_l2=6.816048559942313\n",
      "--- Fold 3 Completed ---\n",
      "train_rmse, test_rmse -  0.06549092795027125 0.06569698324184771\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=3 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0016838659225225001, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0.0016838659225225001\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.816048559942313, reg_lambda=1.0 will be ignored. Current value: lambda_l2=6.816048559942313\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5600550938420944, subsample=0.9 will be ignored. Current value: bagging_fraction=0.5600550938420944\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7571066302658794, colsample_bytree=0.5 will be ignored. Current value: feature_fraction=0.7571066302658794\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=3 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0016838659225225001, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0.0016838659225225001\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.816048559942313, reg_lambda=1.0 will be ignored. Current value: lambda_l2=6.816048559942313\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5600550938420944, subsample=0.9 will be ignored. Current value: bagging_fraction=0.5600550938420944\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7571066302658794, colsample_bytree=0.5 will be ignored. Current value: feature_fraction=0.7571066302658794\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.071283\n",
      "[LightGBM] [Debug] init for col-wise cost 0.000001 seconds, init for row-wise cost 0.002672 seconds\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000909 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Debug] Using Dense Multi-Val Bin\n",
      "[LightGBM] [Info] Total Bins 361\n",
      "[LightGBM] [Info] Number of data points in the train set: 562500, number of used features: 7\n",
      "[LightGBM] [Debug] Use subset for bagging\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=3 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0016838659225225001, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0.0016838659225225001\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.816048559942313, reg_lambda=1.0 will be ignored. Current value: lambda_l2=6.816048559942313\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5600550938420944, subsample=0.9 will be ignored. Current value: bagging_fraction=0.5600550938420944\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7571066302658794, colsample_bytree=0.5 will be ignored. Current value: feature_fraction=0.7571066302658794\n",
      "[LightGBM] [Info] Start training from score 77.000000\n",
      "[LightGBM] [Debug] Re-bagging, using 314587 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 62 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 59 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 59 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 315254 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 61 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 62 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 61 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 314538 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 58 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 56 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 314871 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 51 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 58 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 54 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 59 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 315482 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 56 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 58 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 56 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 56 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 314926 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 61 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 58 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 57 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 58 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 314770 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 57 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 52 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 57 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 56 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 314989 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 58 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 57 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 49 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 47 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 49 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 315855 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 45 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 46 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 46 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 33 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 315350 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 50 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 315366 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 59 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 51 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 59 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 62 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 50 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 315382 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 64 and depth = 6\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 64 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 49 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 58 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 314531 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 62 and depth = 6\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 64 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 58 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 315054 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 44 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 6\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 64 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 61 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 314774 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 57 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 6\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 64 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 62 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 56 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 314918 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 64 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 61 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 62 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 315370 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 59 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 61 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 59 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 58 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 314772 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 56 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 42 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 50 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 314249 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 51 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 61 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 315444 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 58 and depth = 6\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 64 and depth = 6\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 64 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 59 and depth = 6\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0016838659225225001, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0.0016838659225225001\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=3 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7571066302658794, colsample_bytree=0.5 will be ignored. Current value: feature_fraction=0.7571066302658794\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5600550938420944, subsample=0.9 will be ignored. Current value: bagging_fraction=0.5600550938420944\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.816048559942313, reg_lambda=1.0 will be ignored. Current value: lambda_l2=6.816048559942313\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0016838659225225001, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0.0016838659225225001\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=3 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7571066302658794, colsample_bytree=0.5 will be ignored. Current value: feature_fraction=0.7571066302658794\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5600550938420944, subsample=0.9 will be ignored. Current value: bagging_fraction=0.5600550938420944\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.816048559942313, reg_lambda=1.0 will be ignored. Current value: lambda_l2=6.816048559942313\n",
      "--- Fold 4 Completed ---\n",
      "train_rmse, test_rmse -  0.0654390092459682 0.06626083895303075\n",
      "--- Training_Completed ---\n",
      "The average test cross neg_root_mean_squared_error is  0.06587730618542707\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, cross_validate, cross_val_score\n",
    "from sklearn.metrics import root_mean_squared_log_error\n",
    "from xgboost.callback import EarlyStopping\n",
    "from optuna.integration import XGBoostPruningCallback\n",
    "\n",
    "NUMBER_OF_SPLITS = 4\n",
    "    \n",
    "outer_kfold = KFold(n_splits=NUMBER_OF_SPLITS, shuffle=True)\n",
    "\n",
    "list_train_rmse = []\n",
    "list_test_rmse = []\n",
    "\n",
    "for fold_number, (infold_training_indices, infold_test_indices) in enumerate(outer_kfold.split(df_train), 1):\n",
    "\n",
    "    # Pre-processing of training data in kfold\n",
    "    X_train = df_train.loc[infold_training_indices,df_train.columns != TARGET_COLUMN]\n",
    "    y_train = df_train.loc[infold_training_indices,TARGET_COLUMN]\n",
    "\n",
    "    X_train = preprocessing(X_train)\n",
    "    X_train = postprocessing(X_train)\n",
    "\n",
    "    # Pre-processing of training data in kfold for in-fold validation\n",
    "    X_test = df_train.loc[infold_test_indices,df_train.columns != TARGET_COLUMN]\n",
    "    y_test = df_train.loc[infold_test_indices,TARGET_COLUMN]\n",
    "    \n",
    "    X_test = preprocessing(X_test)\n",
    "    X_test = postprocessing(X_test)\n",
    "\n",
    "\n",
    "    hyperparameters = {'boosting_type': 'gbdt',\n",
    "    'class_weight': None,\n",
    "    'colsample_bytree': 0.5,\n",
    "    'importance_type': 'gain',\n",
    "    'learning_rate': 0.11994985788993823,\n",
    "    'max_depth': 6,\n",
    "    'min_child_samples': 10,\n",
    "    'min_child_weight': 0.001,\n",
    "    'min_split_gain': 0.0,\n",
    "    'n_estimators': 100,\n",
    "    'n_jobs': None,\n",
    "    'num_leaves': 64,\n",
    "    'objective': 'regression_l1',\n",
    "    'random_state': 64,\n",
    "    'reg_alpha': 0.1,\n",
    "    'reg_lambda': 1.0,\n",
    "    'subsample': 0.9,\n",
    "    'subsample_for_bin': 200000,\n",
    "    'subsample_freq': 3,\n",
    "    'lambda_l1': 0.0016838659225225001,\n",
    "    'lambda_l2': 6.816048559942313,\n",
    "    'bagging_freq': 5,\n",
    "    'bagging_fraction': 0.5600550938420944,\n",
    "    'feature_fraction': 0.7571066302658794,\n",
    "    'verbosity': 7}\n",
    "\n",
    "    model = lgb.LGBMRegressor(\n",
    "        **hyperparameters,\n",
    "        # callbacks=[EarlyStopping(rounds=50, min_delta=2e-4, maximize=False)],\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_train, \n",
    "        y_train,\n",
    "        eval_set=[(X_test, y_test)],\n",
    "        eval_metric=get_rmsle,\n",
    "    )\n",
    "\n",
    "    y_train_preds = model.predict(X_train)\n",
    "    train_rmse = root_mean_squared_log_error(y_true=y_train,y_pred=y_train_preds)\n",
    "    list_train_rmse.append(train_rmse)\n",
    "\n",
    "    y_test_preds = model.predict(X_test)\n",
    "    test_rmse = root_mean_squared_log_error(y_true=y_test,y_pred=y_test_preds)\n",
    "    list_test_rmse.append(test_rmse)\n",
    "\n",
    "    print(f'--- Fold {fold_number} Completed ---')\n",
    "    print('train_rmse, test_rmse - ',train_rmse,test_rmse)\n",
    "\n",
    "print('--- Training_Completed ---')\n",
    "print('The average test cross neg_root_mean_squared_error is ', sum(list_test_rmse)/len(list_test_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "66506282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average test cross neg_root_mean_squared_error is  0.06587730618542707\n"
     ]
    }
   ],
   "source": [
    "print('The average test cross neg_root_mean_squared_error is ', sum(list_test_rmse)/len(list_test_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "09df8790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=3 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0016838659225225001, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0.0016838659225225001\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.816048559942313, reg_lambda=1.0 will be ignored. Current value: lambda_l2=6.816048559942313\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5600550938420944, subsample=0.9 will be ignored. Current value: bagging_fraction=0.5600550938420944\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7571066302658794, colsample_bytree=0.5 will be ignored. Current value: feature_fraction=0.7571066302658794\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=3 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0016838659225225001, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0.0016838659225225001\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.816048559942313, reg_lambda=1.0 will be ignored. Current value: lambda_l2=6.816048559942313\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5600550938420944, subsample=0.9 will be ignored. Current value: bagging_fraction=0.5600550938420944\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7571066302658794, colsample_bytree=0.5 will be ignored. Current value: feature_fraction=0.7571066302658794\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.071025\n",
      "[LightGBM] [Debug] init for col-wise cost 0.000001 seconds, init for row-wise cost 0.003536 seconds\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001159 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Debug] Using Dense Multi-Val Bin\n",
      "[LightGBM] [Info] Total Bins 360\n",
      "[LightGBM] [Info] Number of data points in the train set: 750000, number of used features: 7\n",
      "[LightGBM] [Debug] Use subset for bagging\n",
      "[LightGBM] [Info] Start training from score 77.000000\n",
      "[LightGBM] [Debug] Re-bagging, using 419610 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 61 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 61 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 59 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 420463 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 62 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 61 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 61 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 58 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 419351 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 59 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 56 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 58 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 419844 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 59 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 59 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 54 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 57 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 420218 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 57 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 56 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 58 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 58 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 420111 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 58 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 56 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 61 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 57 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 56 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 419918 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 56 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 54 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 57 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 419780 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 58 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 47 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 49 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 49 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 49 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 420991 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 49 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 50 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 50 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 49 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 38 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 420399 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 51 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 59 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 59 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 47 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 420304 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 54 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 59 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 58 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 53 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 420163 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 64 and depth = 6\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 64 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 48 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 51 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 59 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 419505 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 62 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 62 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 62 and depth = 6\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 64 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 420205 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 57 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 62 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 62 and depth = 6\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 64 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 419873 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 59 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 61 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 61 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 61 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 56 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 420128 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 64 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 63 and depth = 6\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 64 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 59 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 62 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 420522 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 56 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 51 and depth = 6\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 64 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 57 and depth = 6\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 64 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 419602 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 57 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 59 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 61 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 59 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 55 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 419278 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 64 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 61 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 61 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 61 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 61 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 420536 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 64 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 49 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 62 and depth = 6\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 58 and depth = 6\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 64 and depth = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMRegressor(bagging_fraction=0.5600550938420944, bagging_freq=5,\n",
       "              colsample_bytree=0.5, feature_fraction=0.7571066302658794,\n",
       "              importance_type=&#x27;gain&#x27;, lambda_l1=0.0016838659225225001,\n",
       "              lambda_l2=6.816048559942313, learning_rate=0.11994985788993823,\n",
       "              max_depth=6, min_child_samples=10, num_leaves=64,\n",
       "              objective=&#x27;regression_l1&#x27;, random_state=64, reg_alpha=0.1,\n",
       "              reg_lambda=1.0, subsample=0.9, subsample_freq=3, verbosity=7)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LGBMRegressor</div></div><div><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LGBMRegressor(bagging_fraction=0.5600550938420944, bagging_freq=5,\n",
       "              colsample_bytree=0.5, feature_fraction=0.7571066302658794,\n",
       "              importance_type=&#x27;gain&#x27;, lambda_l1=0.0016838659225225001,\n",
       "              lambda_l2=6.816048559942313, learning_rate=0.11994985788993823,\n",
       "              max_depth=6, min_child_samples=10, num_leaves=64,\n",
       "              objective=&#x27;regression_l1&#x27;, random_state=64, reg_alpha=0.1,\n",
       "              reg_lambda=1.0, subsample=0.9, subsample_freq=3, verbosity=7)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LGBMRegressor(bagging_fraction=0.5600550938420944, bagging_freq=5,\n",
       "              colsample_bytree=0.5, feature_fraction=0.7571066302658794,\n",
       "              importance_type='gain', lambda_l1=0.0016838659225225001,\n",
       "              lambda_l2=6.816048559942313, learning_rate=0.11994985788993823,\n",
       "              max_depth=6, min_child_samples=10, num_leaves=64,\n",
       "              objective='regression_l1', random_state=64, reg_alpha=0.1,\n",
       "              reg_lambda=1.0, subsample=0.9, subsample_freq=3, verbosity=7)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training on entire dataset\n",
    "X_train = df_train.loc[:,df_train.columns != TARGET_COLUMN]\n",
    "y_train = df_train.loc[:,TARGET_COLUMN]\n",
    "\n",
    "X_train = preprocessing(X_train)    \n",
    "X_train = postprocessing(X_train)\n",
    "\n",
    "# Pre-processing of training data in kfold for in-fold validation\n",
    "X_test = df_test\n",
    "\n",
    "X_test = preprocessing(X_test)\n",
    "X_test = postprocessing(X_test)\n",
    "\n",
    "model = lgb.LGBMRegressor(\n",
    "    **hyperparameters,\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train, \n",
    "    y_train,\n",
    "    # eval_metric=get_rmsle,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c9d712",
   "metadata": {},
   "source": [
    "# Test Set Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e230e19b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.0016838659225225001, reg_alpha=0.1 will be ignored. Current value: lambda_l1=0.0016838659225225001\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=3 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7571066302658794, colsample_bytree=0.5 will be ignored. Current value: feature_fraction=0.7571066302658794\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5600550938420944, subsample=0.9 will be ignored. Current value: bagging_fraction=0.5600550938420944\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.816048559942313, reg_lambda=1.0 will be ignored. Current value: lambda_l2=6.816048559942313\n"
     ]
    }
   ],
   "source": [
    "y_preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a7ff3f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Calories</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>750000</th>\n",
       "      <td>88.283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750001</th>\n",
       "      <td>88.283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750002</th>\n",
       "      <td>88.283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750003</th>\n",
       "      <td>88.283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750004</th>\n",
       "      <td>88.283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>88.283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>88.283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>88.283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>88.283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>88.283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Calories\n",
       "id              \n",
       "750000    88.283\n",
       "750001    88.283\n",
       "750002    88.283\n",
       "750003    88.283\n",
       "750004    88.283\n",
       "...          ...\n",
       "999995    88.283\n",
       "999996    88.283\n",
       "999997    88.283\n",
       "999998    88.283\n",
       "999999    88.283\n",
       "\n",
       "[250000 rows x 1 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample_submission "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5127c00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "date = datetime.datetime.now().date().strftime('%Y-%m-%d')\n",
    "\n",
    "model_type = type(model).__name__\n",
    "\n",
    "comment = 'parameters_from_online_notebook_gender_fixed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "173bad6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission = df_sample_submission.copy()\n",
    "df_submission[TARGET_COLUMN] = y_preds.clip(min=0,max=np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "642df921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.8894645380584698)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submission.Calories.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2f299fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the csv to the submissions folder\n",
    "df_submission.to_csv(f'../submissions/{date}-{model_type}-{comment}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5524d49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/05 01:58:56 INFO mlflow.tracking.fluent: Experiment with name 'Kaggle S5E5' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run agreeable-boar-940 at: http://localhost:5000/#/experiments/4/runs/23f97be3a90a4950848fe4bf77852242\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     24\u001b[39m mlflow.log_metric(\u001b[33m\"\u001b[39m\u001b[33mkaggle leaderboard\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m0.16078\u001b[39m)\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Infer the model signature\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m signature = \u001b[43minfer_signature\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_input\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_output\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# Log the model\u001b[39;00m\n\u001b[32m     33\u001b[39m model_info = mlflow.sklearn.log_model(\n\u001b[32m     34\u001b[39m     sk_model=model,\n\u001b[32m     35\u001b[39m     artifact_path=\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     36\u001b[39m     signature=signature,\n\u001b[32m     37\u001b[39m     input_example=X_train,\n\u001b[32m     38\u001b[39m );\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/personal_repos/KAGGLE_S5E5/.venv/lib/python3.12/site-packages/mlflow/models/signature.py:262\u001b[39m, in \u001b[36minfer_signature\u001b[39m\u001b[34m(model_input, model_output, params)\u001b[39m\n\u001b[32m    259\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    260\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    261\u001b[39m         schemas[key] = (\n\u001b[32m--> \u001b[39m\u001b[32m262\u001b[39m             convert_dataclass_to_schema(data) \u001b[38;5;28;01mif\u001b[39;00m is_dataclass(data) \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_infer_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    263\u001b[39m         )\n\u001b[32m    264\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m InvalidDataForSignatureInferenceError:\n\u001b[32m    265\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/personal_repos/KAGGLE_S5E5/.venv/lib/python3.12/site-packages/mlflow/types/utils.py:390\u001b[39m, in \u001b[36m_infer_schema\u001b[39m\u001b[34m(data)\u001b[39m\n\u001b[32m    383\u001b[39m \u001b[38;5;66;03m# pandas.DataFrame\u001b[39;00m\n\u001b[32m    384\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, pd.DataFrame):\n\u001b[32m    385\u001b[39m     schema = Schema(\n\u001b[32m    386\u001b[39m         [\n\u001b[32m    387\u001b[39m             ColSpec(\n\u001b[32m    388\u001b[39m                 \u001b[38;5;28mtype\u001b[39m=_infer_pandas_column(data[col]),\n\u001b[32m    389\u001b[39m                 name=col,\n\u001b[32m--> \u001b[39m\u001b[32m390\u001b[39m                 required=\u001b[43m_infer_required\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    391\u001b[39m             )\n\u001b[32m    392\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m data.columns\n\u001b[32m    393\u001b[39m         ]\n\u001b[32m    394\u001b[39m     )\n\u001b[32m    395\u001b[39m \u001b[38;5;66;03m# numpy.ndarray\u001b[39;00m\n\u001b[32m    396\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, np.ndarray):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/personal_repos/KAGGLE_S5E5/.venv/lib/python3.12/site-packages/mlflow/types/utils.py:516\u001b[39m, in \u001b[36m_infer_required\u001b[39m\u001b[34m(col)\u001b[39m\n\u001b[32m    514\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_infer_required\u001b[39m(col) -> \u001b[38;5;28mbool\u001b[39m:\n\u001b[32m    515\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(col, (\u001b[38;5;28mlist\u001b[39m, pd.Series)):\n\u001b[32m--> \u001b[39m\u001b[32m516\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43many\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_is_none_or_nan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    517\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_none_or_nan(col)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/personal_repos/KAGGLE_S5E5/.venv/lib/python3.12/site-packages/mlflow/types/utils.py:516\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    514\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_infer_required\u001b[39m(col) -> \u001b[38;5;28mbool\u001b[39m:\n\u001b[32m    515\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(col, (\u001b[38;5;28mlist\u001b[39m, pd.Series)):\n\u001b[32m--> \u001b[39m\u001b[32m516\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[43m_is_none_or_nan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m col)\n\u001b[32m    517\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_none_or_nan(col)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/personal_repos/KAGGLE_S5E5/.venv/lib/python3.12/site-packages/mlflow/types/utils.py:509\u001b[39m, in \u001b[36m_is_none_or_nan\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m    507\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_is_none_or_nan\u001b[39m(x):\n\u001b[32m    508\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mfloat\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m509\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43misnan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    510\u001b[39m     \u001b[38;5;66;03m# NB: We can't use pd.isna() because the input can be a series.\u001b[39;00m\n\u001b[32m    511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m pd.NA \u001b[38;5;129;01mor\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m pd.NaT\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# CHECKLIST BEFORE RUNNING\n",
    "# 1. is this a new run (start_run run_id empty) or are you inserting into an old run (start run populated)\n",
    "# 2. Do you know the kaggle leaderboard metric? If not set to 999\n",
    "# 3. Is this a leaderboard model? If not then disable the model logging at the end\n",
    "# This take 2 minutes to run\n",
    "\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "# Set our tracking server uri for logging\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "\n",
    "# Create a new MLflow Experiment\n",
    "mlflow.set_experiment(\"Kaggle S5E5\")\n",
    "\n",
    "# Start an MLflow run\n",
    "with mlflow.start_run():\n",
    "\n",
    "    # Log the hyperparameters\n",
    "    mlflow.log_params(hyperparameters)\n",
    "\n",
    "    # Log the loss metric\n",
    "    mlflow.log_metric(\"cv_score\", sum(list_test_rmse)/len(list_test_rmse))\n",
    "    mlflow.log_metric(\"kaggle leaderboard\", 0.16078)\n",
    "\n",
    "    # Infer the model signature\n",
    "    signature = infer_signature(\n",
    "        model_input=X_train,\n",
    "        model_output=y_train,\n",
    "    )\n",
    "\n",
    "    # Log the model\n",
    "    model_info = mlflow.sklearn.log_model(\n",
    "        sk_model=model,\n",
    "        artifact_path=\"model\",\n",
    "        signature=signature,\n",
    "        input_example=X_train,\n",
    "    );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24bf6c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 27.63488177, 108.07915831,  86.98847049, ...,  64.58244601,\n",
       "       181.35049496,  76.35856799])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
